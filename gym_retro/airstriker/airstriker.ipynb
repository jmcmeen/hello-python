{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gym Retro + NEAT\n",
    "\n",
    "Tested with Python 3.8.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Project: Playing Airstriker with Gym Retro and NEAT\n",
    "Purpose: Evolve a neural network to play Airstriker\n",
    "Notes:\n",
    "  Airstriker game is a non-commercial homebrew game that comes preinstalled with OpenAI Gym Retro\n",
    "\"\"\"\n",
    "\n",
    "import retro  # pip install gym-retro\n",
    "import numpy as np  # pip install numpy\n",
    "import cv2  # pip install opencv-python\n",
    "import neat  # pip install neat-python\n",
    "import pickle  # pip install cloudpickle\n",
    "\n",
    "# create retro environment: game, state, scenario (defines rewards)\n",
    "environment = retro.make('Airstriker-Genesis', 'Level1', scenario='scenario')\n",
    "\n",
    "\n",
    "# define an evaluation function for each game \"play through\" genome\n",
    "def eval_genomes(genomes, config):\n",
    "    # for each genome in the population\n",
    "    for genome_id, genome in genomes:\n",
    "        # reset environment to initial state\n",
    "        observation = environment.reset()\n",
    "\n",
    "        # shape/resolution of image created by emulator\n",
    "        inx, iny, inc = environment.observation_space.shape\n",
    "\n",
    "        # scale down observation\n",
    "        inx = int(inx / 8)\n",
    "        iny = int(iny / 8)\n",
    "\n",
    "        # create NEAT network\n",
    "        network = neat.nn.recurrent.RecurrentNetwork.create(genome, config)\n",
    "\n",
    "        # create an alternative type of neural network with NEAT\n",
    "        # network = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "\n",
    "        # set up some variables to track fitness\n",
    "        fitness = 0\n",
    "\n",
    "        # optionally create another window for the \"neural network's vision\"\n",
    "        # cv2.namedWindow(\"main\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "        finished = False\n",
    "        while not finished:\n",
    "            # render the game\n",
    "            environment.render()\n",
    "\n",
    "            # resize and reshape the observation image\n",
    "            observation = cv2.resize(observation, (inx, iny))\n",
    "            # observation = cv2.cvtColor(observation, cv2.COLOR_BGR2RGB) #alt view\n",
    "            observation = cv2.cvtColor(observation, cv2.COLOR_BGR2GRAY)\n",
    "            observation = np.reshape(observation, (inx, iny))\n",
    "\n",
    "            # optional update \"neural network's vision\"\n",
    "            # cv2.imshow('main', observation)\n",
    "            # cv2.waitKey(1)\n",
    "\n",
    "            # create a single array from 2d pixel data\n",
    "            img_array = np.ndarray.flatten(observation)\n",
    "\n",
    "            # create controller actions from input\n",
    "            actions = network.activate(img_array)\n",
    "\n",
    "            # take a peek at controller actions before translation\n",
    "            # print(actions)\n",
    "\n",
    "            # map relu activation output to 0 or 1\n",
    "            actions = np.where(np.array(actions) <= 0.0, 0.0, 1.0).tolist()\n",
    "\n",
    "            # take a peek at controller actions before translation\n",
    "            # print(actions)\n",
    "\n",
    "            # increment the emulator state\n",
    "            observation, reward, done, info = environment.step(actions)\n",
    "\n",
    "            # update fitness with reward from environment\n",
    "            fitness += reward\n",
    "\n",
    "            if done:\n",
    "                finished = True\n",
    "                print(genome_id, fitness)\n",
    "\n",
    "        # set the fitness for this genome\n",
    "        genome.fitness = fitness\n",
    "\n",
    "\n",
    "# NEAT configuration, all defaults except a config file is provided\n",
    "config = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                     neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                     'config-feedforward')\n",
    "\n",
    "# NEAT output\n",
    "population = neat.Population(config)\n",
    "# population = neat.Checkpointer.restore_checkpoint('neat-checkpoint-13') #code to reload from checkpoint\n",
    "population.add_reporter(neat.StdOutReporter(True))\n",
    "stats = neat.StatisticsReporter()\n",
    "population.add_reporter(stats)\n",
    "population.add_reporter(neat.Checkpointer(10))\n",
    "\n",
    "# the winning network, run for x generations\n",
    "winner = population.run(eval_genomes, 1000)\n",
    "\n",
    "# save the winning network to a binary file to reload later\n",
    "with open('winner-act1.pkl', 'wb') as output:\n",
    "    pickle.dump(winner, output, 1)\n",
    "\n",
    "exit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
